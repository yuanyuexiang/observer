#!/usr/bin/env python3
"""
è§†é¢‘æµå·¥å…·æ£€æµ‹ç³»ç»Ÿ
æ”¯æŒæ‘„åƒå¤´å®æ—¶æ£€æµ‹å’Œè§†é¢‘æ–‡ä»¶æ£€æµ‹
"""
import cv2
import time
import json
import threading
from datetime import datetime
from pathlib import Path
from production_tool_detector import ProductionToolDetector, SystemConfig
import numpy as np

class VideoStreamDetector:
    """è§†é¢‘æµå·¥å…·æ£€æµ‹å™¨"""
    
    def __init__(self, config: SystemConfig, detection_interval=2.0):
        """
        åˆå§‹åŒ–è§†é¢‘æµæ£€æµ‹å™¨
        
        Args:
            config: ç³»ç»Ÿé…ç½®
            detection_interval: æ£€æµ‹é—´éš”ï¼ˆç§’ï¼‰
        """
        self.detector = ProductionToolDetector(config)
        self.detection_interval = detection_interval
        self.last_detection_time = 0
        self.last_results = None
        self.is_detecting = False
        
        # åŠ è½½å·¥ä½œç©ºé—´é…ç½®
        workspace_config_path = Path("instances_default.json")
        if workspace_config_path.exists():
            # ä½¿ç”¨detectorçš„æ–¹æ³•æ¥æ­£ç¡®è§£æCOCOæ ¼å¼
            self.workspace_config = self.detector.load_workspace_configuration("instances_default.json")
        else:
            raise FileNotFoundError("å·¥ä½œç©ºé—´é…ç½®æ–‡ä»¶ instances_default.json æœªæ‰¾åˆ°")
    
    def detect_frame_async(self, frame):
        """å¼‚æ­¥æ£€æµ‹å¸§"""
        if self.is_detecting:
            return
            
        current_time = time.time()
        if current_time - self.last_detection_time < self.detection_interval:
            return
            
        self.is_detecting = True
        self.last_detection_time = current_time
        
        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œæ£€æµ‹
        detection_thread = threading.Thread(
            target=self._detect_frame_worker,
            args=(frame.copy(),)
        )
        detection_thread.daemon = True
        detection_thread.start()
    
    def _detect_frame_worker(self, frame):
        """æ£€æµ‹å·¥ä½œçº¿ç¨‹"""
        try:
            # ä¿å­˜ä¸´æ—¶å›¾ç‰‡
            temp_path = "temp_frame.jpg"
            cv2.imwrite(temp_path, frame)
            
            # è¿è¡Œæ£€æµ‹
            results = self.detector.run_full_detection(temp_path, self.workspace_config)
            self.last_results = results
            
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            Path(temp_path).unlink(missing_ok=True)
            
        except Exception as e:
            print(f"âŒ æ£€æµ‹é”™è¯¯: {e}")
        finally:
            self.is_detecting = False
    
    def draw_results_overlay(self, frame):
        """åœ¨å¸§ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœè¦†ç›–å±‚"""
        if not self.last_results:
            return frame
            
        height, width = frame.shape[:2]
        overlay = frame.copy()
        
        # é¦–å…ˆç»˜åˆ¶æ‰€æœ‰å·¥å…·çš„æ£€æµ‹æ¡†
        for result in self.last_results:
            if hasattr(result, 'bbox') and result.bbox and len(result.bbox) >= 4:
                # è·å–bboxåæ ‡ [x, y, width, height]
                x, y, w, h = result.bbox
                x1, y1 = int(x), int(y)
                x2, y2 = int(x + w), int(y + h)
                
                # æ ¹æ®æ£€æµ‹çŠ¶æ€é€‰æ‹©é¢œè‰²
                if result.status == "present":
                    bbox_color = (0, 255, 0)  # ç»¿è‰²
                    text_bg_color = (0, 200, 0)
                elif result.status == "missing":
                    bbox_color = (0, 0, 255)  # çº¢è‰²
                    text_bg_color = (0, 0, 200)
                else:  # uncertain
                    bbox_color = (0, 255, 255)  # é»„è‰²
                    text_bg_color = (0, 200, 200)
                
                # ç»˜åˆ¶æ£€æµ‹æ¡†
                cv2.rectangle(overlay, (x1, y1), (x2, y2), bbox_color, 3)
                
                # ç»˜åˆ¶å·¥å…·åç§°èƒŒæ™¯
                tool_text = f"{result.tool_name}"
                text_size = cv2.getTextSize(tool_text, cv2.FONT_HERSHEY_SIMPLEX, 0.6, 2)[0]
                cv2.rectangle(overlay, (x1, y1 - 30), (x1 + text_size[0] + 10, y1), text_bg_color, -1)
                
                # ç»˜åˆ¶å·¥å…·åç§°
                cv2.putText(overlay, tool_text, (x1 + 5, y1 - 8), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)
                
                # ç»˜åˆ¶ç½®ä¿¡åº¦ï¼ˆåœ¨æ¡†çš„å³ä¸‹è§’ï¼‰
                conf_text = f"{result.confidence:+.3f}"
                conf_size = cv2.getTextSize(conf_text, cv2.FONT_HERSHEY_SIMPLEX, 0.5, 1)[0]
                cv2.rectangle(overlay, (x2 - conf_size[0] - 10, y2), (x2, y2 + 20), text_bg_color, -1)
                cv2.putText(overlay, conf_text, (x2 - conf_size[0] - 5, y2 + 15), 
                           cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 1)
        
        # åˆ›å»ºåŠé€æ˜èƒŒæ™¯
        result_bg = np.zeros((height, width, 3), dtype=np.uint8)
        
        # ç»Ÿè®¡ä¿¡æ¯
        present_count = sum(1 for r in self.last_results if r.status == "present")
        missing_count = sum(1 for r in self.last_results if r.status == "missing")
        uncertain_count = sum(1 for r in self.last_results if r.status == "uncertain")
        total_count = len(self.last_results)
        
        # ç»˜åˆ¶çŠ¶æ€æ 
        status_height = 200
        cv2.rectangle(result_bg, (0, 0), (width, status_height), (50, 50, 50), -1)
        
        # æ ‡é¢˜
        cv2.putText(overlay, "Tool Detection System", (20, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)
        
        # ç»Ÿè®¡ä¿¡æ¯
        stats_text = f"Total: {total_count} | Present: {present_count} | Missing: {missing_count} | Uncertain: {uncertain_count}"
        cv2.putText(overlay, stats_text, (20, 65), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 1)
        
        # å®Œæ•´æ€§ç™¾åˆ†æ¯”
        completeness = (present_count / total_count * 100) if total_count > 0 else 0
        completeness_text = f"Completeness: {completeness:.1f}%"
        color = (0, 255, 0) if completeness >= 90 else (0, 255, 255) if completeness >= 70 else (0, 0, 255)
        cv2.putText(overlay, completeness_text, (20, 95), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2)
        
        # è¯¦ç»†å·¥å…·çŠ¶æ€
        y_offset = 130
        for i, result in enumerate(self.last_results):
            if i >= 8:  # æœ€å¤šæ˜¾ç¤º8ä¸ªå·¥å…·
                break
                
            status_icon = "âœ“" if result.status == "present" else "âœ—" if result.status == "missing" else "?"
            status_color = (0, 255, 0) if result.status == "present" else (0, 0, 255) if result.status == "missing" else (0, 255, 255)
            
            tool_text = f"{status_icon} {result.tool_name}"
            cv2.putText(overlay, tool_text, (20, y_offset), 
                       cv2.FONT_HERSHEY_SIMPLEX, 0.5, status_color, 1)
            y_offset += 20
        
        # æ··åˆè¦†ç›–å±‚
        cv2.addWeighted(overlay, 0.8, result_bg, 0.3, 0, overlay)
        
        # æ·»åŠ æ£€æµ‹çŠ¶æ€æŒ‡ç¤ºå™¨
        if self.is_detecting:
            cv2.circle(overlay, (width - 30, 30), 10, (0, 255, 255), -1)  # é»„è‰²ï¼šæ£€æµ‹ä¸­
        else:
            cv2.circle(overlay, (width - 30, 30), 10, (0, 255, 0), -1)   # ç»¿è‰²ï¼šå°±ç»ª
        
        return overlay
    
    def run_camera_detection(self, camera_id=0):
        """è¿è¡Œæ‘„åƒå¤´æ£€æµ‹"""
        print(f"ğŸ¥ å¯åŠ¨æ‘„åƒå¤´æ£€æµ‹ (è®¾å¤‡ID: {camera_id})")
        print("æŒ‰ 'q' é€€å‡º, æŒ‰ 's' ä¿å­˜å½“å‰å¸§, æŒ‰ 'r' æ‰‹åŠ¨è§¦å‘æ£€æµ‹")
        
        cap = cv2.VideoCapture(camera_id)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€æ‘„åƒå¤´ {camera_id}")
            return
        
        # è®¾ç½®æ‘„åƒå¤´å‚æ•°
        cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)
        cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)
        
        while True:
            ret, frame = cap.read()
            if not ret:
                print("âŒ æ— æ³•è¯»å–æ‘„åƒå¤´ç”»é¢")
                break
            
            # å¼‚æ­¥æ£€æµ‹
            self.detect_frame_async(frame)
            
            # ç»˜åˆ¶ç»“æœè¦†ç›–å±‚
            display_frame = self.draw_results_overlay(frame)
            
            # æ˜¾ç¤ºç”»é¢
            cv2.imshow('Tool Detection - Real Time', display_frame)
            
            # å¤„ç†æŒ‰é”®
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q'):
                break
            elif key == ord('s'):
                # ä¿å­˜å½“å‰å¸§
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"capture_{timestamp}.jpg"
                cv2.imwrite(filename, frame)
                print(f"ğŸ“¸ å·²ä¿å­˜: {filename}")
            elif key == ord('r'):
                # æ‰‹åŠ¨è§¦å‘æ£€æµ‹
                self.last_detection_time = 0
                print("ğŸ”„ æ‰‹åŠ¨è§¦å‘æ£€æµ‹...")
        
        cap.release()
        cv2.destroyAllWindows()
        print("ğŸ¥ æ‘„åƒå¤´æ£€æµ‹å·²åœæ­¢")
    
    def run_video_file_detection(self, video_path):
        """è¿è¡Œè§†é¢‘æ–‡ä»¶æ£€æµ‹"""
        print(f"ğŸ¬ å¯åŠ¨è§†é¢‘æ–‡ä»¶æ£€æµ‹: {video_path}")
        
        if not Path(video_path).exists():
            print(f"âŒ è§†é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {video_path}")
            return
        
        cap = cv2.VideoCapture(video_path)
        if not cap.isOpened():
            print(f"âŒ æ— æ³•æ‰“å¼€è§†é¢‘æ–‡ä»¶: {video_path}")
            return
        
        total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
        fps = cap.get(cv2.CAP_PROP_FPS)
        
        print(f"è§†é¢‘ä¿¡æ¯: {total_frames} å¸§, {fps:.2f} FPS")
        print("æŒ‰ 'q' é€€å‡º, æŒ‰ 's' ä¿å­˜å½“å‰å¸§, æŒ‰ç©ºæ ¼æš‚åœ/ç»§ç»­")
        
        frame_count = 0
        paused = False
        
        while True:
            if not paused:
                ret, frame = cap.read()
                if not ret:
                    print("ğŸ¬ è§†é¢‘æ’­æ”¾å®Œæ¯•")
                    break
                frame_count += 1
            
            # å¼‚æ­¥æ£€æµ‹
            if not paused:
                self.detect_frame_async(frame)
            
            # ç»˜åˆ¶ç»“æœè¦†ç›–å±‚
            display_frame = self.draw_results_overlay(frame)
            
            # æ·»åŠ è¿›åº¦æ¡
            progress = frame_count / total_frames
            bar_width = display_frame.shape[1] - 40
            cv2.rectangle(display_frame, (20, display_frame.shape[0] - 30), 
                         (20 + int(bar_width * progress), display_frame.shape[0] - 20), 
                         (0, 255, 0), -1)
            
            # æ˜¾ç¤ºç”»é¢
            cv2.imshow('Tool Detection - Video File', display_frame)
            
            # æ§åˆ¶æ’­æ”¾é€Ÿåº¦
            delay = int(1000 / fps) if fps > 0 else 33
            key = cv2.waitKey(delay) & 0xFF
            
            if key == ord('q'):
                break
            elif key == ord('s'):
                # ä¿å­˜å½“å‰å¸§
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"video_frame_{frame_count}_{timestamp}.jpg"
                cv2.imwrite(filename, frame)
                print(f"ğŸ“¸ å·²ä¿å­˜: {filename}")
            elif key == ord(' '):
                paused = not paused
                print(f"â¸ï¸ {'æš‚åœ' if paused else 'ç»§ç»­'}")
        
        cap.release()
        cv2.destroyAllWindows()
        print("ğŸ¬ è§†é¢‘æ£€æµ‹å·²åœæ­¢")

def main():
    """ä¸»å‡½æ•°"""
    import sys
    
    if len(sys.argv) < 2:
        print("""
ğŸ¥ è§†é¢‘æµå·¥å…·æ£€æµ‹ç³»ç»Ÿ

ä½¿ç”¨æ–¹æ³•:
  python video_stream_detector.py camera [camera_id]     # æ‘„åƒå¤´æ£€æµ‹ (é»˜è®¤ID=0)
  python video_stream_detector.py video <video_path>     # è§†é¢‘æ–‡ä»¶æ£€æµ‹

æ§åˆ¶é”®:
  q - é€€å‡º
  s - ä¿å­˜å½“å‰å¸§
  r - æ‰‹åŠ¨è§¦å‘æ£€æµ‹ (ä»…æ‘„åƒå¤´æ¨¡å¼)
  ç©ºæ ¼ - æš‚åœ/ç»§ç»­ (ä»…è§†é¢‘æ–‡ä»¶æ¨¡å¼)

ç¤ºä¾‹:
  python video_stream_detector.py camera 0
  python video_stream_detector.py video sample_video.mp4
        """)
        return
    
    command = sys.argv[1].lower()
    
    # é…ç½®æ£€æµ‹ç³»ç»Ÿ
    config = SystemConfig(
        confidence_threshold=0.0005,
        uncertainty_threshold=-0.0001,
        save_roi_images=False,
        log_level="ERROR"  # å‡å°‘æ§åˆ¶å°è¾“å‡º
    )
    
    detector = VideoStreamDetector(config, detection_interval=1.5)  # 1.5ç§’æ£€æµ‹é—´éš”
    
    try:
        if command == "camera":
            camera_id = int(sys.argv[2]) if len(sys.argv) > 2 else 0
            detector.run_camera_detection(camera_id)
        elif command == "video":
            if len(sys.argv) < 3:
                print("âŒ è¯·æä¾›è§†é¢‘æ–‡ä»¶è·¯å¾„")
                return
            video_path = sys.argv[2]
            detector.run_video_file_detection(video_path)
        else:
            print(f"âŒ æœªçŸ¥å‘½ä»¤: {command}")
            
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç³»ç»Ÿ")
    except Exception as e:
        print(f"âŒ è¿è¡Œé”™è¯¯: {e}")

if __name__ == "__main__":
    main()